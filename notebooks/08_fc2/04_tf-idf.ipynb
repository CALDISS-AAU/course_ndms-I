{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebde7dbb-a1aa-4a4b-9543-8331f0c01adc",
   "metadata": {},
   "source": [
    "# Alternative vægtning af ord: Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e15c58b-d867-4451-a165-bad542e4a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep\n",
    "import pandas as pd\n",
    "\n",
    "redditdata_url = \"https://raw.githubusercontent.com/CALDISS-AAU/course_ndms-I/master/datasets/reddit_rdenmark-comments_01032021-08032021_long.csv\"\n",
    "reddit_df = pd.read_csv(redditdata_url)\n",
    "\n",
    "# Lagr kommentarer i objekt for sig\n",
    "comments = list(reddit_df['comment_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e69c57d-7ff9-4bb4-9591-463e507fa1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/opt/tljh/user/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "and             1030.215344\n",
       "godt             956.913994\n",
       "0a               889.633384\n",
       "folk             824.060511\n",
       "tror             784.250825\n",
       "danmark          702.441635\n",
       "ja               673.972109\n",
       "mener            576.901141\n",
       "reddit           521.875816\n",
       "post             521.061035\n",
       "mennesker        508.005891\n",
       "altså            506.789185\n",
       "this             506.301846\n",
       "10               505.611269\n",
       "your             493.331144\n",
       "was              460.064083\n",
       "they             451.199899\n",
       "nej              444.399787\n",
       "gerne            444.041004\n",
       "hudfarve         434.692586\n",
       "with             433.242678\n",
       "can              430.311353\n",
       "tid              416.148416\n",
       "or               401.557440\n",
       "faktisk          397.597595\n",
       "store            395.447939\n",
       "gå               394.361830\n",
       "gang             389.137133\n",
       "finde            387.448525\n",
       "youtube          386.872070\n",
       "spørgsmål        383.697482\n",
       "blevet           380.980331\n",
       "penge            380.020513\n",
       "on               379.686488\n",
       "giver            364.751838\n",
       "removed          364.499029\n",
       "dag              362.491478\n",
       "måde             360.923462\n",
       "bedre            357.525841\n",
       "danske           356.426583\n",
       "woke             349.131839\n",
       "langt            346.525845\n",
       "enig             338.717579\n",
       "racisme          336.440017\n",
       "tak              335.602531\n",
       "as               334.945969\n",
       "selvfølgelig     333.736438\n",
       "deleted          329.674589\n",
       "if               329.495878\n",
       "står             327.969160\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-idf vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "custom_stops = ['gt', 'bare', 'the', 'to', 'når', 'https', 'helt', 'of', 'se', 'in', 'www', 'is', 'you', 'dk', 'får', 'com', 'ret', 'it', 'that', 'år', 'siger',\n",
    "               'hele', 'går', 'ting', 'ser', 'del', 'vel', 'tage', 'set', 'are', 'be', 'not', 'but', 'amp']\n",
    "\n",
    "stops = list(nlp.Defaults.stop_words) + custom_stops\n",
    "\n",
    "# Indstil tfidf vectorizer - samme indstillinger som før\n",
    "vectorizer = TfidfVectorizer(stop_words = stops, max_df = 0.7, norm = False)\n",
    "transformed_documents = vectorizer.fit_transform(comments)\n",
    "\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Konverter array til document-term matrix\n",
    "df = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names())\n",
    "\n",
    "# Ordoptælling\n",
    "word_tfidfsum = df.sum()\n",
    "word_tfidfsum.sort_values(ascending = False)[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366fb61d-f364-4dce-bdd5-9eef4abef897",
   "metadata": {},
   "source": [
    "## Tf-idf vectorizer på eksisterende tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41735c37-b937-4f41-a688-d2342c245f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion brugt til at tokenize data\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"da_core_news_sm\", disable = ['parser', 'ner', 'textcat'])\n",
    "\n",
    "def tokenizer_spacy(text):\n",
    "    custom_stops = ['gt', 'bare', 'the', 'to', 'når', 'https', 'helt', 'of', 'se', 'in', 'www', 'is', 'you', 'dk', 'får', 'com', 'ret', 'it', 'that', 'år', 'siger',\n",
    "               'hele', 'går', 'ting', 'ser', 'del', 'vel', 'tage', 'set', 'are', 'be', 'not', 'but', 'amp']\n",
    "    stop_words = list(nlp.Defaults.stop_words) + custom_stops\n",
    "    pos_tags = ['PROPN', 'ADJ', 'NOUN']\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for word in doc:\n",
    "        if (len(word.lemma_) == 1):\n",
    "            continue\n",
    "        if (word.pos_ in pos_tags) and (word.lemma_.lower() not in stop_words):\n",
    "            tokens.append(word.lemma_.lower())\n",
    "                \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad326f47-a9cb-4f73-ae94-924c76627189",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['comment_tokens'] = reddit_df['comment_body'].apply(tokenizer_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6992670-7e5d-47ee-b257-270c4e3cf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danner kopi af data\n",
    "\n",
    "reddit_df_tokenized = reddit_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6ec384-62a4-4641-90cb-6fbe920cee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evt. indlæs allerede eksisterende tokenized data\n",
    "#import ast\n",
    "#reddit_df_tokenized = pd.read_csv(\"https://raw.githubusercontent.com/CALDISS-AAU/course_ndms-I/master/datasets/reddit_rdenmark_q=danmark_01012020-30062020_long_filtered_tokenized.zip\")\n",
    "#reddit_df_tokenized['tokens'] = reddit_df_tokenized['tokens'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610aa36a-e2cf-4373-b510-9aa258ccbe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "reddit_df_tokenized = reddit_df_tokenized.loc[reddit_df_tokenized['comment_tokens'].apply(lambda tokens: len(tokens) > 1), :]\n",
    "\n",
    "# Lagr kommentarer for sig\n",
    "comments_tokens = list(reddit_df_tokenized['comment_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81751bc-e5a2-4701-b804-06ccb26f7c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stor           901.406928\n",
       "mangen         838.125205\n",
       "folk           837.013857\n",
       "danmark        669.056656\n",
       "gang           578.774272\n",
       "dag            555.953102\n",
       "tid            544.925037\n",
       "menneske       533.505473\n",
       "sted           526.474988\n",
       "problem        514.573896\n",
       "land           508.198903\n",
       "dansk          501.083232\n",
       "post           489.244964\n",
       "this           485.154182\n",
       "megen          437.335389\n",
       "penge          433.956820\n",
       ":)             423.219724\n",
       "måde           392.845121\n",
       "spørgsmål      381.216330\n",
       "hudfarve       377.147660\n",
       "your           376.522772\n",
       "barn           374.841476\n",
       "can            363.060509\n",
       "enig           362.971874\n",
       "person         353.184309\n",
       "they           346.897431\n",
       "kommentar      338.380978\n",
       "racisme        330.677148\n",
       "woke           322.475365\n",
       "rette          317.033151\n",
       "parre          313.326193\n",
       "with           310.564095\n",
       "side           309.919958\n",
       "tak            304.622722\n",
       "sidste         302.260032\n",
       "måned          294.094532\n",
       "parti          292.922775\n",
       "forhold        291.092509\n",
       "if             287.140770\n",
       "usa            286.743633\n",
       "krone          286.400804\n",
       "godte          278.512171\n",
       "stemme         275.664425\n",
       "høj            275.614458\n",
       "arbejde        271.651863\n",
       "eu             266.329204\n",
       "israel         263.565940\n",
       "job            262.620419\n",
       "rigtig         262.620419\n",
       "information    262.398681\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tfidfvectorizer på tokens\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Dummyfunktion - bruges som tokenizer-funktion i vectorizer\n",
    "def return_tokens(tokens):\n",
    "    return tokens\n",
    "\n",
    "# Indstiller vectorizer med brug af dummyfunktion (returnerer blot tokens, da data allerede er tokenized)\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=return_tokens,\n",
    "    preprocessor=return_tokens,\n",
    "    token_pattern=None,\n",
    "    norm = False)\n",
    "\n",
    "# Fitter vectorizer\n",
    "transformed_documents = vectorizer.fit_transform(comments_tokens)\n",
    "\n",
    "# Konverter til array\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Konverter til document-term matrix\n",
    "df = pd.DataFrame(transformed_documents_as_array, columns = vectorizer.get_feature_names())\n",
    "\n",
    "# Ordoptælling\n",
    "word_tfidfsum = df.sum().sort_values(ascending = False)\n",
    "word_tfidfsum[0:50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
