{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "### Hvad er det, hvorfor er det og hvad foregår der?\n",
    "\n",
    "![RT](https://images.boredomfiles.com/wp-content/uploads/2017/08/tree-3-e1503676886163-768x419.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Random Forests\" er en del af de usuperviserede algoritmer der bruges til f.eks. at klassificere \"ting\".\n",
    "\n",
    "Så, hvad er klassificering? Klassificering er et begreb appliceret til de algoritmer der er designet til at *\"se\"* på ting og bestemme hvad de er.\n",
    "\n",
    "![horse](https://i.pinimg.com/736x/10/5e/47/105e476496fbd538090c7daeb529c3bf.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Så hvor ser vi klassificering? Alle steder!\n",
    "\n",
    "Amazon prøver at sælge jer til? Klassificering! Lufthavne scanner ting? Klassificering! Instagram censurerer billeder? You guess it... klassificering!\n",
    "\n",
    "Fordelen ved klassificeringsalgoritmer er, at det sparer uendelig meget tid. Det kan grovsortere, det kan indfange og det kan hjælpe til, at vi ikke længere behøver, manuelt, at forholde os til samtlige elementer af generelt super kedelige ting. Hvem gider i virkeligheden kigge på kartofler hele dagen:\n",
    "\n",
    "![potato](https://forbo.blob.core.windows.net/forbodocuments/507685/HD-Potato%20quality%20control%20at%20Avico.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I rå produktion er klassificering for alvor en opgradering (hvis vi ikke tager diskussionen om elimineringen af jobs op).\n",
    "\n",
    "Kvalitetssikring er næsten 100% reduceret til klassificering nu, hvor selv folk hjemme i deres garage kan bygge en simpel maskine der sparer en del tid:\n",
    "\n",
    "https://www.youtube.com/watch?v=A29IqeahI84\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short; klassificering er implementeret vildt mange steder, men hvordan kan det hjælpe os? Hvad har kartofler at gøre med socialvidenskab?\n",
    "\n",
    "***More than you know, young Skywalker!***\n",
    "\n",
    "Vi kan inddele klassificering brugt i samfundsvidenskab (meget groft) i to overordnede parametre: \n",
    "\n",
    "* Klassificering brugt til at sige noget om fordelinger\n",
    "* Klassificering brugt til at prædiktere \"hændelser\"\n",
    "\n",
    "Vi skal i dag primært kigge på klassificering til at prædiktere hændelser - nærmere betegnet skal vi kigge på, om vi kan prædiktere risiko for depression/angst i ukendt data ved at træne på data der allerede har labels.\n",
    "\n",
    "\n",
    "\n",
    "#### Begreber vi helt sikkert skal have styr på, før vi kaster os ud i skovene:\n",
    "\n",
    "* Decision trees \n",
    "* Bagging\n",
    "* Test og træningssæt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees\n",
    "\n",
    "***Decision trees*** er en måde at håndtere data der består af en række valg på:\n",
    "\n",
    "![dt](https://cdn-images-1.medium.com/max/824/0*J2l5dvJ2jqRwGDfG.png)\n",
    "\n",
    "Et enkelt træ bygger på ideen om, at vi vil vide, hvor meget information hver gren af træet tilføjer vores endelige beslutning når vi skal bestemme noget. Som eksempel vil vi gerne vide, hvor meget følgende ting hjælper os til at forstå, om vi får en god dag i morgen:\n",
    "\n",
    "|Solskin|Søvn dagen før|Marmorkugler i køleskabet|\n",
    "|-------|--------------|-------------------------|\n",
    "|Ja/Nej|Ja/Nej   |          Ja/Nej|\n",
    "\n",
    "I ovenstående eksempel kan vi nok godt regne med, at søvn dagen før er ret vigtig, vejr er relativt vigtigt og hvorvidt vi har marmorkugler i køleskabet er meget lidt vigtigt (med mindre det er det eneste vi har - så er det nok ret vigtigt).\n",
    "\n",
    "Vi kan ikke orke at skulle regne det hele ud, så i stedet applicerer vi noget der kaldes ***Shannon's Entropy***:\n",
    "\n",
    "$$\\LARGE H(X)=\\sum^n_{{i=1}} p(x_i)ln \\frac{1}{p(x_i)}$$\n",
    "\n",
    "* $p(x_i)$ = andelen af populationen ($x$) der falder i en bestemt kategori ($i$)\n",
    "* $ln$ = den naturlige logaritme\n",
    "* $\\sum^n_{{i=1}}$ = summering af det totale\n",
    "\n",
    "Hvad betyder det i praksis? Det betyder at vi reelt set måler på, hvor meget information vi har af den totale information i den andel vi kigger på.\n",
    "\n",
    "I vores eksempel vil vi gerne vide, hvor meget henholdvis solskin, søvn og marmorkugler hjælper os med den samlede information, som er om vi får en god dag. Hver af de elementer \"tilbyder\" en procentvis information til det fulde billede vil et decision tree hælde til at vælge den \"gren\" der fortæller os mest om, hvordan i morgen bliver. På den måde vil træet vide, hvad det skal kigge på og hvornår noget hælder til \"god dag\".\n",
    "\n",
    "Shannons entropy er måske lidt irriterende at kigge på, men den er intuitiv let af forholde sig til hvis vi ser på den i forhold til biologi og særligt i forhold til artsdiversitet. Biologer bruger f.eks. $H$ til at sige noget om, hvor mange arter der eksisterer i et givent miljø (tænk \"isoleret ø\" og \"hvor mange forskellige slags dyr\"). Den her version af $H$ er \"låst\" mellem 0 og 1. I vores ø-eksempel betyder det, at:\n",
    "\n",
    "* 1=fuld diversitet - alle arterne fyder lige meget\n",
    "* 0=der er kun én art\n",
    "\n",
    "Tænkt i vores eksempel kan vi overføre det til, hvorvidt hver gren på vores træ indeholder al informationen til at vide, om det bliver en god dag eller ikke noget som helst. Hvordan ved modellen, at informationen fører fra f.eks. solskin -> god dag? Den kigger! Det betyder, at den allerede har informationen (eller i hvert fald for en del af data) om hvorvidt der var solskin, om folk sov dagen før og om der er marmorkugler i køleskabet. Mere om det senere.\n",
    "\n",
    "Entropien er en *hjælper* - det sker automatisk i modellerne og vi behøver ikke regne det ud :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "![bag](https://www.cmbiomass.com/wp-content/uploads/2018/07/bagging-operation-banner-1-1198x425.jpg)\n",
    ".... ikke den slags bagging. Den her slags:\n",
    "\n",
    "![real_bag](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/1920px-Ensemble_Bagging.svg.png)\n",
    "\n",
    "Vi nærmer os langsomt en skov... bagging (også kaldet bootstrap aggregering) baserer sig på flere forskellige træer og ikke bare et. Normalt bygger vi et decision tree op omkring al information omkring det samme træ; vi samler, med andre ord, alt det vi kan for at tage én stor beslutning i ét træ. Bagging er næste skridt.\n",
    "\n",
    "Ved bagging deler vi samplet op i tilfældige grupper, bygger træer og tester så, hvilke kombinationer af baggrundsvariable (solskin, søvn og marmorkugler) der resulterer i en god dag.\n",
    "\n",
    "Hvorfor er træet ikke nok? Fordi træet egentlig bare stiller spørgsmålet til alle mennesker på én gang. Den tester forskellige kombinationer af variable til at få det rigtige svar, men det er altid bare med alle vores respondenter på én gang. Grunden til vi er bekymret for det er, at det kommer til at lære vores datasæt ekstremt godt (fordi det hele tiden har hele samplet), men det kommer til at klare sig markant dårligere når der kommer \"ny\" information ind. Vi vil helst have, at den kan lave analyser på mere data end det vi har... for der kender vi jo allerede svaret på, om folk får en god dag.\n",
    "\n",
    "Bagging deler menneskerne op i forskellige grupper (træer) og forsøger at svare på samme spørgsmål; god dag? På den måde tvinger man konstant de forskellige grupper af mennesker (og deres tilhørende træer) til at blive en lille smule forskellige. Gruppe 1 har måske brug for lidt mere solskin, mens gruppe 2 er meget afhængige af søvn, osv.\n",
    "\n",
    "Når vi har \"nok\" forskellige vil modellen prøve at lave en form for aggregat af træerne og så komme med en brugbar model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "Nu har vi en generel ide om, hvordan de indledende øvelser til random forests fungerer, men vi mangler et helt essentielt skridt på vejen; train/test-split data. Et helt generelt problem i superviseret machine learning er, at de lærer for meget for hurtigt. Hvorfor er det et problem?\n",
    "\n",
    "Lad os sige, at det vi beder modellen kigge på, er hvorvidt noget er en melon eller... ikke en melon. Vi viser den en masse billeder vi har fundet af meloner og så billeder af ting der ikke er meloner... f.eks. hvaler, rumskibe og Flemming fra grillen. Vi har ikke tænkt os helt vildt godt om da vi fandt billeder af meloner, så vi har primært bare fundet dem Rema sælger. De har vand-, net- og honningmeloner men de har ikke lige Galiameloner på lager. Ydermere finder vi mest bare billeder af meloner som de ser ud i reklamner. Pludselig beder vi modellen om at kigge på den her:\n",
    "\n",
    "![rottenmelon](http://ransborons.scoilnet.ie/blog/files/2010/11/P1000178-300x225.jpg)\n",
    "\n",
    "Den er rådden, underlig og klam og ligner slet ikke de meloner der er i reklamerne. Modellen skal kun forholde sig til, om det er en melon eller ikke en melon og det vi viser den nu er mega meget ikke noget den har set før. Den bliver stresset og tænker: \"Det bliver et stor nej herfra\" og smider den i bunken med hvaler, rumskibe og Flemming. Hvorfor? Fordi vi ikke har trænet den generelt men i stedet ekstremt specifikt. Hvis vi KUN træner modellen til at forudsige de ting vi allerede har vist den så er den i virkeligheden super dum - den gentager det vi allerede ved. Vi har brug for, at den husker alt fra meget specifikke detaljer til meget generelle ting som resulterer i at den i langt højere grad kan sige noget om ting den aldrig har set.\n",
    "\n",
    "Opgaven bliver derfor, at tvinge modellen ikke til KUN at lære alt om præcis hvad vi giver den. Hvordan holder vi øje med, at det er det der sker? You guessed it; train/test-split! Hurtig visualisering:\n",
    "\n",
    "![tt-split](https://miro.medium.com/max/656/0*FKrWuLRbB_MiEIKh)\n",
    "\n",
    "Basalt set indeholder al vores data stadig de rigtige svar. Alle billederne af meloner har en \"label\" der hedder melon eller ikke melon. Nu har vi bare været smarte - vi \"gemmer\" noget af data for modellen som vi siger til den, at den faktisk slet ikke må kigge på. Det er hemmeligt. Ratioerne for hvad man træner på og hvad man gemmer væk varierer, men for det meste vil i se 90%-10%, 80%-20% eller 70%-30%. Når den så har trænet på f.eks. de 80% og fundet ud af, hvad den skal kigge på for at det virker der, så beder vi den om at tage den model og prøve den af på test-sættet, de sidste 20%. Hvis den har lært noget ekstremt specifikt på de 80% vil den klare sig elendigt på de sidste 20%. Hvis den har lært noget generelt og brugbart, så vil forskellen på test og træning være meget lille.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# BOOM!\n",
    "\n",
    "Vi har nu al den information vi har brug for, før vi begynder at lege med tilfældige skove. Let's get to it!\n",
    "\n",
    "Lad os importere ting... først i vores script som fornuftige mennesker! Den samme slags mennesker, der (selvfølgelig) putter toiletpapiret på holderen den rigtige vej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                         #pandas stuff\n",
    "from sklearn.model_selection import train_test_split        #Den dingenot der splitter data op på den \"rigtige\" måde\n",
    "from sklearn.ensemble import RandomForestClassifier         #En del af sklearn der har random forests i sig\n",
    "import numpy as np                                          #Numpy\n",
    "from sklearn import metrics                                 #Til at måle hvor godt vores skov klarer sig\n",
    "from sklearn.inspection import permutation_importance       #Til at forsøge at finde ud af, hvad der er vigtigt i modellen af de ting vi serverer den\n",
    "from matplotlib import pyplot as plt                        #matplotlib fordi jeg er virkelig elendig til seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Før vi i det hele taget gør andet, så lad os gøre os bekendt med data. Data er scramblet sundhedsprofil-data (rigtig data jeg har lavet pjatværk med). Variablene inkluderet er følgende:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data](https://i.ibb.co/0y4p2fH/hep-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lad os få proppet data ind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp3</th>\n",
       "      <th>angstdep</th>\n",
       "      <th>sp13d</th>\n",
       "      <th>sp13e</th>\n",
       "      <th>sp17</th>\n",
       "      <th>sp60a</th>\n",
       "      <th>sp60b</th>\n",
       "      <th>sp60c</th>\n",
       "      <th>sp60d</th>\n",
       "      <th>sp60e</th>\n",
       "      <th>...</th>\n",
       "      <th>sp63a</th>\n",
       "      <th>sp63b</th>\n",
       "      <th>sp69</th>\n",
       "      <th>sp75</th>\n",
       "      <th>alder</th>\n",
       "      <th>binge</th>\n",
       "      <th>nybmi</th>\n",
       "      <th>samliv</th>\n",
       "      <th>nyudd</th>\n",
       "      <th>kon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sp3 angstdep sp13d sp13e sp17 sp60a sp60b sp60c sp60d sp60e  ... sp63a  \\\n",
       "0   3        1     2     3    5     2     1     2     2     3  ...     1   \n",
       "1   2        0     2     2    5     2     3     2     3     5  ...     1   \n",
       "2   2        0     2     2    5     1     2     2     2     5  ...     1   \n",
       "3   2        1     2     3    5     2     2     4     3     4  ...     2   \n",
       "4   2        0     3     2    5     1     2     1     2     5  ...     1   \n",
       "\n",
       "  sp63b sp69 sp75 alder  binge nybmi samliv  nyudd kon  \n",
       "0     1    1    1    42      2     4      1      4   1  \n",
       "1     1    1    1    40      2     3      1      4   2  \n",
       "2     1    1    1    45      2     4      1      4   2  \n",
       "3     2    2    2    62      2     3      1      4   1  \n",
       "4     1    1    1    44      2     3      1      5   1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep = pd.read_csv(\"https://github.com/RolfLund/NDSM/raw/main/hep_snit.csv\", low_memory=False)\n",
    "dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miniøvelse! \n",
    "\n",
    "Brug lige 10 minutter på at få pillet lidt ved de her variable. Hvad er interessant her? Får i nogle interessante spørgsmål? Hvad kunne være interessant at forsøge at lave en eller anden form for prædiktion på?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ... aaaaand theeeeeen?\n",
    "\n",
    "Jeg har lavet et spørgsmål. Mit spørgsmål er, om vi kan blive bedre til at prædiktere hvem der i risikogruppe for at få angst og/eller depression.... I know, I know, det er lidt dystert, men det er til gengæld også super relevant i f.eks. forebyggelse på socialområdet.\n",
    "\n",
    "Før vi gør andet, så bestemmer vi os lige for at tjekke hvordan de tro grupper opfører sig (husk på det der med, at de fleste af de her ML-tests bedst kan lide nogenlunde balance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "angstdep\n",
       ".a      598\n",
       "0     17147\n",
       "1     19352\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep.groupby(['angstdep']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![zeus](https://i.pinimg.com/originals/af/f6/2d/aff62dd44edd30d2abb711bf1dd9c7ee.gif)\n",
    "\n",
    "Man skulle næsten tro, at jeg rent faktisk havde planlagt, at vi skulle bruge den variabel til i dag!\n",
    "\n",
    "En anden ting vi har brug for, er at vores variable opfører sig ordentligt. Ikke noget med tekst eller andet skrammel midt i en ellers udmærket numerisk variabel. Vi tjekker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37097 entries, 0 to 37096\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sp3       37097 non-null  object\n",
      " 1   angstdep  37097 non-null  object\n",
      " 2   sp13d     37097 non-null  object\n",
      " 3   sp13e     37097 non-null  object\n",
      " 4   sp17      37097 non-null  object\n",
      " 5   sp60a     37097 non-null  object\n",
      " 6   sp60b     37097 non-null  object\n",
      " 7   sp60c     37097 non-null  object\n",
      " 8   sp60d     37097 non-null  object\n",
      " 9   sp60e     37097 non-null  object\n",
      " 10  sp62      37097 non-null  object\n",
      " 11  sp63a     37097 non-null  object\n",
      " 12  sp63b     37097 non-null  object\n",
      " 13  sp69      37097 non-null  object\n",
      " 14  sp75      37097 non-null  object\n",
      " 15  alder     37097 non-null  int64 \n",
      " 16  binge     37097 non-null  object\n",
      " 17  nybmi     37097 non-null  object\n",
      " 18  samliv    37097 non-null  int64 \n",
      " 19  nyudd     37097 non-null  object\n",
      " 20  kon       37097 non-null  int64 \n",
      "dtypes: int64(3), object(18)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det ser... mildest talt forfærdeligt ud. Hvordan ser en tilfældig variaben ud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '2', '4', '1', '5', '.a'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep.sp3.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MY EYES! En super simpel måde vi kan forcere vores data til at opføre sig ordentligt på er:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dep.columns:\n",
    "    dep[col] = pd.to_numeric(dep[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is it that we laver? Vi looper over alle kolonnerne i vores dataframe (dep) og beder dem om at blive skiftet ud med numeriske værdier. Hvis de smider en error (fordi der er en ikke-tal værdi) så tillader \"coerce\" at vi bare trumler dem og så bliver de værdier til missing (nan). Vi smider lige nan ud (for god ordens skyld og så tjekker vi hvordan vores sp3 ser ud bagefter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep=dep.dropna()\n",
    "dep.angstdep.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endelig opfører data sig som det skal - vi er nået til et punkt hvor vi reelt set kan lege med at definere hvad vi gerne vil prædiktere og hvad vi gerne vil prædiktere med. Fordi jeg har skåret datasættet lidt hårdt her, så kan jeg tillade mig at bruge hele skidtet som prædiktorer. Jeg skal, med andre ord, ikke til at døje med at vælge (**BEMÆRK** Det skal man normalt): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dep['angstdep']\n",
    "x=dep.drop(['angstdep'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lille huske-note her; Pandas taler tit om *axis*. Axis er Pandas måde at specificere, om det er kolonner eller rækker vi taler om. Axis=0 er rækker, mens axis=1 er kolonner.\n",
    "\n",
    "Let's have a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "Name: angstdep, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp3</th>\n",
       "      <th>sp13d</th>\n",
       "      <th>sp13e</th>\n",
       "      <th>sp17</th>\n",
       "      <th>sp60a</th>\n",
       "      <th>sp60b</th>\n",
       "      <th>sp60c</th>\n",
       "      <th>sp60d</th>\n",
       "      <th>sp60e</th>\n",
       "      <th>sp62</th>\n",
       "      <th>sp63a</th>\n",
       "      <th>sp63b</th>\n",
       "      <th>sp69</th>\n",
       "      <th>sp75</th>\n",
       "      <th>alder</th>\n",
       "      <th>binge</th>\n",
       "      <th>nybmi</th>\n",
       "      <th>samliv</th>\n",
       "      <th>nyudd</th>\n",
       "      <th>kon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sp3  sp13d  sp13e  sp17  sp60a  sp60b  sp60c  sp60d  sp60e  sp62  sp63a  \\\n",
       "0  3.0    2.0    3.0   5.0    2.0    1.0    2.0    2.0    3.0   1.0    1.0   \n",
       "1  2.0    2.0    2.0   5.0    2.0    3.0    2.0    3.0    5.0   1.0    1.0   \n",
       "2  2.0    2.0    2.0   5.0    1.0    2.0    2.0    2.0    5.0   1.0    1.0   \n",
       "3  2.0    2.0    3.0   5.0    2.0    2.0    4.0    3.0    4.0   1.0    2.0   \n",
       "4  2.0    3.0    2.0   5.0    1.0    2.0    1.0    2.0    5.0   1.0    1.0   \n",
       "\n",
       "   sp63b  sp69  sp75  alder  binge  nybmi  samliv  nyudd  kon  \n",
       "0    1.0   1.0   1.0     42    2.0    4.0       1    4.0    1  \n",
       "1    1.0   1.0   1.0     40    2.0    3.0       1    4.0    2  \n",
       "2    1.0   1.0   1.0     45    2.0    4.0       1    4.0    2  \n",
       "3    2.0   2.0   2.0     62    2.0    3.0       1    4.0    1  \n",
       "4    1.0   1.0   1.0     44    2.0    3.0       1    5.0    1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun begins! Som i måske husker, så har vi importeret\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "Det er en fancy pakke der lader os lave de der splits vi har snakket om. Som i husker, så har vi brug for\n",
    "\n",
    "* Træningssæt X (Prædiktorer til at træne modellen med)\n",
    "* Træningssæt Y (Outcome vi træner modellen til at prædiktere)\n",
    "* Testsæt X     (Prædiktorer vi \"gemmer\" for modellen som den ikke har set)\n",
    "* Testsæt Y     (Outcome vi \"gemmer\" for modellen som den ikke har set)\n",
    "\n",
    "Det kan, helst simpelt, gørest ved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Så skal jeres random forest classifier \"bygges\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clas=RandomForestClassifier(n_estimators=100)\n",
    "rf_clas.fit(x_train,y_train)\n",
    "y_pred=rf_clas.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi bygger vores random forest classifier ved at gemme den som en funktion vi kan applicere senere. I vores funktion har vi kun én ting vi specificerer og det er n_estimators. Estimatorerne er, basalt set, hvor mange træer vi vil bygge før vi lader modellen stoppe og give sit gæt. Jo flere træer, jo klogere bliver den, men det har også en pris. For det første bliver koden langsommere ved at bruge flere. For det andet kan man komme til at overestimere; den bliver igen alt for god til at holde øje med alle de mikroskopiske ting i data som *måske* betyder noget men som måske også bare er anomalier i data. En videnskabelig tilgang til valg af estimatorer involverer det der kaldes *\"hyper parameter tuning\"* som er udenfor dette valgfags scope. En god tommelfingerregl er mellem 100 og 1000 i langt de fleste tilfælde. En måde at teste det på vil være at bygge flere forskellige modeller med flere forskellige n estimatorer og sammenligne performance.\n",
    "\n",
    "Performance, som vi berører lige nu, handler udelukkende om, hvor mange procent modellen gætter rigtigt i det data vi har brugt. Det kan vi tjekke ved at sige:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis vi gerne vil sammenligne hvor godt den gætter på træningsdata versus test-data kan vi sige:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train accuracy: 1.000\n",
      "RF test accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "print(\"RF train accuracy: %0.3f\" % rf_clas.score(x_train, y_train))\n",
    "print(\"RF test accuracy: %0.3f\" % rf_clas.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miniøvelse!\n",
    "\n",
    "Prøv at skifte i estimator-antallet og se om det ændrer i modellen! Hvad virker? Hvad sker der hvis i f.eks. vælger 10?\n",
    "\n",
    "And now, for something completely different! Feature importance! En irriterende kritik af modellerne her er, at vi har enormt svært ved at gennemskue, hvilke ting der betyder noget for vores model. Vi kan ikke, ligesom i regression, sige noget om koefficienterne fordi vi (basically) er pænt ligeglade. Vi vil gerne, at vores model er god til at forudsige ting. En måde man kan tvinge vores model til at sige noget, er ved at bruge feature importance.\n",
    "\n",
    "Feature importance bygger på tanken om, at hvert trå i vores skov har betyning for modellen. Ved at \"slette\" træer tilfæligt og forsøge at forudsige noget, så kan vi også finde ud af, hvor meget hver element i vores skov siger for udfaldet. En kikset og ubrugelig oversigt over feature importance kan fremtvinges ved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08878262, 0.08021366, 0.03264847, 0.04022853, 0.04272663,\n",
       "       0.0438403 , 0.05176133, 0.05394199, 0.0506359 , 0.04498864,\n",
       "       0.08615195, 0.05794719, 0.04133227, 0.01870107, 0.11984215,\n",
       "       0.01013681, 0.0404965 , 0.01820867, 0.05594227, 0.02147306])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clas.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Men det kan vi ikke bruge til så meget. Det er en array af værdier som kan tolkes i retninge af hvor mange procent hvert element har betydning for udfaldet. Det er ikke eksakt fordi det beror på hvad der sker når man fjerner et element og beholder de andre. Vi kan derfor snildt havne i en situation, hvor vi er både over og under 100%. Det ignorerer vi lige nu.\n",
    "\n",
    "For at få det til at give mening kan vi i stedet plotte det som en graf. Wupti:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd4838327d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(rf_clas.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(4).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovenfor har jeg valgt de 4 vigtigste features i min random forest. Jeg kan også bare plotte det hele ved at sige:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 20 artists>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(x.columns, rf_clas.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Men det er afskyeligt fordi min graf ikke er sorteret efter høj til lav. Ad. Det kan vi fikse ved at sige:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Tilfældige skove og vigtighed')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted = rf_clas.feature_importances_.argsort()\n",
    "fig, ax = plt.subplots()\n",
    "plt.barh(x.columns[sorted], rf_clas.feature_importances_[sorted])\n",
    "ax.set_title(\"Tilfældige skove og vigtighed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Her til sidst!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, så hvor god er random forest i forhold til f.eks. en logistisk regression? Vi er så heldige, at logistisk regression også sagtens kan bruges som en klassificeringsalgoritme i sklearn. Jeg bryder nu min egen regel og importerer noget til sidst (AAAAADDDD!) i en notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistisk regression i sklearn er rimelig ligetil. Vi definerer modellen først ved at gemme funktionen logistisk regression i \"logit\" for derefter at fitte den til vores data. Lige for nu ignorerer vi, hvad en \"solver\" er for noget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(solver='liblinear')\n",
    "logit.fit(x_train, y_train)\n",
    "y_pred=logit.predict(x_test)\n",
    "print(\"Accuracy: %0.3f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Til sidst kan vi printe præcision ligesom ved RF. Hvor godt kan vores logistiske regression \"gætte\" hvad udfaldet er i data, som den aldrig har set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ØVELSESTID!!!\n",
    "\n",
    "Nu er det Jeres tur; brug enten jeres eget data eller brug data fra dagens forelæsning til at bygge jeres egen tilfældige skov. Det eneste i skal være opmærksomme på lige nu er:\n",
    "\n",
    "* I skal have data af en hvis størrelse (helst +10K)\n",
    "* I kan godt ignorere, at jeres udfaldskategorier ikke er lige store - det er altid interessant at ignorere :D\n",
    "* I skal sikre jer, at jeres udfald er dikotomt - only dummies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
